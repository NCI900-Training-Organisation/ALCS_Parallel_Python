{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef08840",
   "metadata": {},
   "source": [
    "![jax.png](jax.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c7c1c5",
   "metadata": {},
   "source": [
    "* JAX is a library that enables transformations of array-manipulating programs written with a NumPy-like API\n",
    "* JAX - NumPy that runs on accelerators\n",
    "* Optimized for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1cbb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2326f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "np_x = np.arange(10)\n",
    "print(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af8ebee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71211ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "jnp_x = jnp.arange(10)\n",
    "print(jnp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd6ddc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaxlib.xla_extension.Array"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(jnp_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc10714",
   "metadata": {},
   "source": [
    "* Same code can be run on different backends – CPU, GPU and TPU.\n",
    "* when a JAX function is called the corresponding operation is dispatched to an accelerator to be computed **asynchronously** when possible. \n",
    "* This means that if we don’t require the result immediately, the computation won’t block Python execution\n",
    "* Unless we **block_until_ready** or convert the array to a regular Python type, we will only time the dispatch, not the actual computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d22b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.15 ms ± 135 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "long_vector = jnp.arange(int(1e7))\n",
    "\n",
    "%timeit jnp.dot(long_vector, long_vector).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1749d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makse sure the function JAX operates on does not have side effects\n",
    "# A side-effect is any effect of a function that doesn’t appear in its output\n",
    "\n",
    "\n",
    "def in_place_modify(x):\n",
    "    x[0] = 123\n",
    "    return None\n",
    "\n",
    "# This function modifies argument, but returns a completely unrelated value. The modification is a side-effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a53b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_place_modify(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc509b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123   1   2   3   4   5   6   7   8   9]\n"
     ]
    }
   ],
   "source": [
    "print(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "375e8574",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<class 'jaxlib.xla_extension.Array'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43min_place_modify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp_x\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36min_place_modify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21min_place_modify\u001b[39m(x):\n\u001b[0;32m----> 6\u001b[0m     x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m123\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:5083\u001b[0m, in \u001b[0;36m_unimplemented_setitem\u001b[0;34m(self, i, x)\u001b[0m\n\u001b[1;32m   5078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unimplemented_setitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, i, x):\n\u001b[1;32m   5079\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object does not support item assignment. JAX arrays are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5080\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimmutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5081\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor another .at[] method: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5082\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 5083\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: '<class 'jaxlib.xla_extension.Array'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html"
     ]
    }
   ],
   "source": [
    "# This will result in an error. \n",
    "# JAX arrays won’t allow themselves to be modified in-place\n",
    "# Unlike NumPy arrays, JAX arrays are always immutable\n",
    "in_place_modify(jnp_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a891685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jax_in_place_modify(x):\n",
    "  return x.at[0].set(123)\n",
    "\n",
    "y = jax_in_place_modify(jnp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a5233eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123   1   2   3   4   5   6   7   8   9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# The old array is untocuhed. No side effects\n",
    "print(y)\n",
    "print(jnp_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2f772",
   "metadata": {},
   "source": [
    "## JIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea71ff48",
   "metadata": {},
   "source": [
    "Just-in-time compilation happen in two ways in JAX:\n",
    "\n",
    "* Automatically: JIT compilation happens under the hood by default when doing library calls of JAX functions.\n",
    "* Manually: You can manually ask for a JIT compilation of your own Python functions using jax.jit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5c3233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.96 ms ± 79.3 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Scaled Exponential Linear Unit (SELU), an operation commonly used in deep learning\n",
    "def selu(x, alpha=1.67, lambda_=1.05):\n",
    "  return lambda_ * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = jnp.arange(1000000)\n",
    "%timeit selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1710db40",
   "metadata": {},
   "source": [
    "* XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra \n",
    "* It can accelerate TensorFlow models with potentially no source code changes\n",
    "\n",
    "* In the code above one operation beibg send at a time to the accelerator\n",
    "* This limits the ability of the XLA compiler to optimize our functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c37d1",
   "metadata": {},
   "source": [
    "* Optimaly , what we want to do is give the XLA compiler as much code as possible\n",
    "* This will alloe XLA tofully optimize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX provides the jax.jit transformation, which will JIT compile a JAX-compatible function. \n",
    "\n",
    "# defined selu_jit as the compiled version of selu\n",
    "selu_jit = jax.jit(selu)\n",
    "\n",
    "# The first run very efficient code optimized for your GPU or TPU\n",
    "selu_jit(x).block_until_ready()\n",
    "\n",
    "#time the execution speed of the compiled version\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd5751",
   "metadata": {},
   "source": [
    "## Automatic differentiation with jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a63477c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.19661197 0.10499357]\n"
     ]
    }
   ],
   "source": [
    "# gradient of the original function\n",
    "# very useful for machine learning \n",
    "\n",
    "def sum_logistic(x):\n",
    "  return jnp.sum(1.0 / (1.0 + jnp.exp(-x)))\n",
    "\n",
    "x_small = jnp.arange(3.)\n",
    "derivative_fn = jax.grad(sum_logistic)\n",
    "print(derivative_fn(x_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dcd6f7",
   "metadata": {},
   "source": [
    "## Parallel Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f159b3c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "compiling computation that requires 3 logical devices, but only 1 XLA devices are available (num_replicas=3, num_partitions=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 4\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/jax/_src/interpreters/pxla.py:1567\u001b[0m, in \u001b[0;36mfrom_hlo\u001b[0;34m(xla_computation, pci, replicas, parts, shards, tuple_args, unordered_effects, ordered_effects, host_callbacks, keepalive)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: compiling computation that requires 3 logical devices, but only 1 XLA devices are available (num_replicas=3, num_partitions=1)"
     ]
    }
   ],
   "source": [
    "x = jnp.arange(3 * 2 * 2.).reshape((3, 2, 2))\n",
    "y = jnp.arange(3 * 2 * 2.).reshape((3, 2, 2)) ** 2\n",
    "\n",
    "out = jax.pmap(jnp.dot)(x, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646604f",
   "metadata": {},
   "source": [
    "# Manually move data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc959fa",
   "metadata": {},
   "source": [
    "* JAX automatically moves data to the device\n",
    "* But we can do it manually as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68ac21df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device_put' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mnormal(key, (size, size), dtype\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mdevice_put\u001b[49m(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device_put' is not defined"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(0)\n",
    "size = 3000\n",
    "x = random.normal(key, (size, size), dtype=jnp.float32)\n",
    "\n",
    "x = device_put(x)\n",
    "\n",
    "# The output of device_put() still acts like an NDArray, but it only copies values back to the CPU \n",
    "# when they’re needed for printing, plotting, saving to disk, branching etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1136f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
